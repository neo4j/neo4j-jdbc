[#s2c_introduction]
= SQL to Cypher translation

== Introduction

The translation of queries from SQL to Cypher is an optional feature of this driver and it consists of two parts:

- The translator SPI, located in the module `{group-id}:neo4j-jdbc-translator-spi`.
It consists of two interfaces: `SqlTranslatorFactory` and the actual `SqlTranslator`.
- A concrete implementation of this SPI, published as `{group-id}:neo4j-jdbc-translator-impl`.

The latter is covered in "xref:s2c[]" and available in the "full bundle", described in xref:distribution.adoc#available_bundles[Available bundles].
The former is provided for two reasons: it allows us to distribute the driver with and without the bundled, default translator and allows you to run your custom translator.

Translators can be chained, and there can be as many translators on the classpath as you want.
Their precedence is configurable, with our default implementation having the lowest precedence.
Thus, you can for example have a custom translator that takes care of a fixed set of queries and, if it receives a query it cannot translate, it will pass it down to our implementation.

Translating arbitrary SQL queries to Cypher is an opinionated task, as there is no right way to map table names to graph objects: a table name can be used as-is as a label, or may be transformed into a singular form, etc. Mapping relationships is even trickier: should relationship types derive from a join table, a join column (in that case, which one?), or a foreign key?

We believe our assumptions are appropriate for various use cases and instead of providing configuration to cater for all scenarios, we offer the possibility to write your own translation layer.
The driver will use the standard Java service loader mechanism to find an implementation of the SPI on the module- or classpath.

NOTE: Some tools (like Tableau) use a class-loader that won't let the driver use the standard Java service loader mechanism.
For these scenarios, we provide an additional configuration property named `translatorFactory`.
Set this to `DEFAULT` to directly load our default implementation or to a fully-qualified classname for any other factory.
*Be aware* that either our default implementation or your custom one must be on the classpath.

== Translating SQL to Cypher

There's only one requirement to enable the SQL-to-Cypher translation: you have to have one module implementing the SPI on the classpath.
This is *automatically* the case if you use the full-bundle (`{group-id}:{artifact-id-full-bundle}`).
In that case, you *don't* need to add any other dependency.
If you use the individual distribution or the "small" bundle `{group-id}:{artifact-id-bundle}`, you must add the artifact `{group-id}:{artifact-id-impl}`.

The implementation will be automatically loaded.
If you use the translation on a case-by-case basis, it will be lazily loaded (i.e no additional classes are touched or loaded into memory).
If you configure automatic translation for all statements, the implementation will be eagerly loaded.
There are no further configuration options with regard to loading the implementation.

=== On a case-by-case basis

The translator can be used on a case-by-case basis through the official JDBC API `nativeSQL`, which you find on the `java.sql.Connection` class.
With the following imports:

[source, java, tabsize=4]
----
include::{examplesDir}/java/SQLTranslator.java[tag=imports]
----

You just pass your SQL statement to `nativeSQL` and you will get Cypher back:

[source, java, tabsize=4, indent=0]
----
include::{examplesDir}/java/SQLTranslator.java[tag=pt1]
----

=== For all queries

If you open the connection to your Neo4j instance using `enableSQLTranslation=true` either as URL parameter or configuration property, all statements will be translated from SQL to Cypher.
If you configure the driver in this way, the translator will be eagerly loaded.

[source, java, tabsize=4, indent=0]
----
include::{examplesDir}/java/SQLTranslator.java[tag=pt2]
----

Sometimes you may need to fall back to Cypher for some statements, either to use constructs that you cannot express with SQL, or because our default translator cannot handle your query.
We offer a special comment that you can use as a hint in your statement to stop automatic translation: `/*+ NEO4J FORCE_CYPHER */`.

[source, java, tabsize=4, indent=0]
----
include::{examplesDir}/java/SQLTranslator.java[tag=force-cypher]
----

=== Possible error scenarios

A `NoSuchElementException` with a message of `No SQL translators available` will be thrown when there is no implementation of the SQL to Cypher translator available, and you either used `java.sql.Connection.nativeSQL` or enabled automatic translation. The exception will be thrown when you access the method or eagerly on opening a connection in the latter case.

[#s2c]
== Using the default translator

=== Supported SQL dialects

Our default translator uses the OSS parser from https://www.jooq.org[jOOQ], which supports a broad spectrum of SQL dialects already.
We picked the generic, default dialect of jOOQ as our default dialect, but you can overwrite this in the SQL to Cypher configuration using the parameter `s2c.sqlDialect` with one of the supported dialects listed in <<s2c_configuration, configuration below>>.
`POSTGRES` can be a good choice for several integrations.

Bear in mind though that any shortcomings in the translation are probably not due to a lack in the parser, but due to the lack of an obvious, semantically equivalent Cypher construct.
That means we might be able to parse a certain piece of SQL, but are unable to translate in into something meaningful that Neo4j can understand without additional, contextual information.


[#s2c_configuration]
=== Configuration

The default implementation provides a number of configuration settings.
**They must be prefixed with `s2c` in the URL or config options:**

|===
|Name |Meaning|Default

|`parseNameCase`
|Whether to parse table names as is or not.
|`true`

|`tableToLabelMappings`
|A map from table names to labels.
|An empty map

|`joinColumnsToTypeMappings`
|A map from column names to relationship types.
|An empty map

|`prettyPrint`
|Whether to format the generated Cypher or not.
|`true`

|`alwaysEscapeNames`
|Whether to always escape names.
|Unless explicitly configured `false` when pretty printing is on, otherwise `true`.

|`sqlDialect`
|Which dialect to use when parsing. Supported values are `POSTGRES`, `SQLITE`, `MYSQL`, `H2`, `HSQLDB`, `DERBY` and `DEFAULT`.
|`DEFAULT`

|`relationshipPattern`
|The pattern that is used for automatically inferring a relationship from a table-name.^1^
|A pattern that matches `ALabel_RELATIONSHIP_TYPE_AnotherLabel` (i.e. relationship type **must** be upper-case and can contain underscores)

|===

[NOTE]
^1^ The pattern must be a valid regular expression  with three capturing groups: First group will be interpreted as start
or left-hand-side node, second group will be interpreted as the relationship type and the third as end or right-hand-side node.
Named groups `lhs`, `reltype` and `rhs` are supported too. `null` or a blank pattern disables automatic inference.

The next few examples use the `properties` config to avoid terrible long URLs in this documentation, but all the attributes can be specified via URL as well.

[source, java, tabsize=4, indent=0]
.Disable pretty printing; only escape if necessary; configure dedicated table mappings
----
include::{examplesDir}/java/SQLTranslator.java[tag=config1]
----

[source, java, tabsize=4, indent=0]
.Parse table names into upper case
----
include::{examplesDir}/java/SQLTranslator.java[tag=config2]
----

Named parameter syntax in the SQL parser defaults to `:name` (such as supported by Oracle, JPA, Spring, a colon followed by a name).
The following example changes that prefix to `$` (the same prefix that Cypher uses):

[source, java, tabsize=4, indent=0]
.Change parameters prefix and add mappings for join columns
----
include::{examplesDir}/java/SQLTranslator.java[tag=config3]
----

This is helpful when a tool generates names like that and does not allow customization.

[#s2c_supported_statements]
=== Supported statements

The following statements are all under tests and describe what you can expect from the default translation layer:

include::translator/simple.adoc[leveloffset=+2]

include::translator/expressions.adoc[leveloffset=+2]

include::translator/predicates.adoc[leveloffset=+2]

include::translator/joins.adoc[leveloffset=+2]

include::translator/dml.adoc[leveloffset=+2]

[#s2c_manipulating_relationships]
=== Manipulating relationships

Relationships in Neo4j involve three entities: A start node, the relationship itself and an end node. Using Cypher, this can be expressed in one statement:

[source,cypher]
----
CREATE (a:Person {name: 'Jaret Leto'})
       -[:ACTED_IN {role: 'Ares'}]->
       (m:Movie {title: 'TRON Ares'})
RETURN *;
----

Which gives you this graph:

image::movie_rel.png[]

In SQL on the other hand, we would normally use at least two or depending on the level of normalisation, three tables to store this
(Think `people`, `movies` and  `acted_in` as intersection table, referencing both `people` and `movies` and storing any properties).

While you can obviously `SELECT` from as many relations as you can think of, the `INSERT` clause in SQL does not support multiple targets of insertion, only a single table.
Without such a construct, the SQL to Cypher translator cannot directly translate a SQL statement into a pattern like the one above.
The translator can only try to infer an intention here on best effort base.

==== Inferring relationships from tables based on existing data

Assuming the above statement was executed, the JDBC driver will actually show that relationship as virtual table in the database metadata:

image::movie_rel_virtual_table.png[]

Having one relationship as this is enough for the JDBC driver to use it as a kind of template. The JDBC driver will query for a relationship-virtual-table based on the given table name and if that matches, automatically infer that the following SQL statement does target a relationship:

[source,sql]
----
INSERT INTO Person_ACTED_IN_Movie(name, role, title)
VALUES('Jodie Turner-Smith', 'Athena', 'TRON Ares');
----

The updated graph looks like this:

image::after_first_insert.png[]

Noteable things are

- No additional `Movie` node has been created
- The attributes `name` has been used with the `Person` label and `title` with the `Movie`
- `role` has been used on the relationship

The matching has been based on the virtual table. If both nodes had had a `name` attribute, the property would have been used on both.
Columns that match neither properties of the nodes nor the relationship, will be added to the relationship.
The `INSERT` statement also was not translated into a plain `CREATE …` statement as shown above.
Inserting into a relationship expresses a pretty clear intention to create the relationship alone, hence the JDBC driver will always create a statement such as this, if possible:

[source,cypher]
----
MERGE (lhs:LabelLeft {propN: 'Value'})
MERGE (rhs:LabelRight {propM: 'Value'})
CREATE (lhs)-[:TYPE]->(rhs);
----

All properties for the nodes will be used for merging. If the JDBC driver cannot match any property to a label, it will issue a `CREATE` statement for that label.

[TIP]
If you can, make sure you define a unique constraint on the properties of the nodes on which you are going to insert relationships, for performance reasons, but also to account for Neo4js `MERGE` behaviour. Under concurrent updates, MERGE only guarantees the existence of the MERGE pattern, but not uniqueness, see https://neo4j.com/docs/cypher-manual/current/clauses/merge/[MERGE].

This works the same way with a multiple values. A statement like the following:

[source,sql]
----
INSERT INTO Person_ACTED_IN_Movie(name, role, title) VALUES
 ('Gillian Anderson', 'Elisabeth Dillinger', 'TRON Ares'),
 ('Arturo Castro', 'Seth Flores', 'TRON Ares');
----

or a batched JDBC variant such as follows:

[source,java]
----
try (var statement = connection.prepareStatement("""
    INSERT INTO Person_ACTED_IN_Movie(name, role, title)
    VALUES (?, ?, ?)""")
) {
    statement.setString(1, "Jeff Bridges");
    statement.setString(2, "Kevin Flynn");
    statement.setString(3, "TRON Ares");
    statement.addBatch();
    statement.setString(1, "Greta Lee");
    statement.setString(2, "Eve Kim");
    statement.setString(3, "TRON Ares");
    statement.executeBatch();
}
----

Will be translated into a Cypher query utilizing `UNWIND` and thus being great for batch loading relationships.

==== Inferring relationships based on the table name

The translator is by default configured in such a way that it tries to infer a relationship from the name of the table that should be inserted into if there's neither a matching existing relationship nor a node with the same label:

Target table of the `INSERT` clause is: `Person_ACTED_IN_Movie`:

* A relationship `(:Person)-[:ACTED_IN]->(:Movie)` exists: This relationship and the properties of all its constituents will be used as template
* A node with the label `Person_ACTED_IN_Movie` exists: `INSERT` clause will be translated into `CREATE (n:Person_ACTED_IN_Movie)`, no attempt of creating relationships will be made
* Otherwise, as `Person_ACTED_IN_Movie` matches the default pattern nodes labeled `Person` and `Movie` will either be merged or created, and a new relationship `ACTED_IN` will be created

The default pattern to infer a relationship is designed in such a way that it detects labels in mixed-case letters that might contain underscores as well separated by a single underscore on each site from a relationship type in upper case, i.e. `Person_ACTED_IN_Movie` will be detected as well as `A_RELATES_TO_B`.
The latter will use labels `A` and `B` for nodes, and `RELATES_TO` for the relationship type.

Without an existing template, we need a way to map properties to the source or the target node or the relationship. By default, all properties will be put onto the relationship when the relationship has been inferred by just the table name.

The JDBC driver however can utilize a SQL feature that lets you qualify columns like this:

[source,sql]
----
INSERT INTO Person_ACTED_IN_Movie(Person.name, ACTED_IN.role, Movie.title)
VALUES ('Evan Peters', 'Julian Dillinger', 'TRON Ares');
----

Now, most SQL databases won't support qualified columns in an `INSERT` statement, but it's valid SQL, and we can parse it. The above qualified columns will be appropriately distributed onto `Person`, `Movie` and `ACTED_IN`.

==== Deleting relationships

While Samuel L. Jackson did play in a lot of movies, he didn't play himself in `TRON: Legacy` and you might want to delete that relationship from the Graph:

image::tronwrong.png[]

This is possible with an ordinary `DELETE FROM` statement on which the inference of relationships works the same way as described above. Aligned with the start and end nodes being merged if possible during create and not modified otherwise, the deletion will only affect the relationship itself:

[source,sql]
----
DELETE FROM Person_ACTED_IN_Movie
WHERE title = 'TRON: Legacy'
  AND name = 'Samuel L. Jackson'
  AND role = 'himself'
----

Predicates will be pushed down in such a way that they filter on the correct target (here: The `name` property of the `:Actor` node, `title` on `:Movie` and `role` on the relationship `:ACTED_IN`). The result can be confirmed with Cypher (the JDBC driver does not support outer joins):

[source,cypher]
----
/*+ NEO4J FORCE_CYPHER */
MATCH (p:Person {name: 'Samuel L. Jackson'})
RETURN p.name, COUNT {(p)-[:ACTED_IN]->(:Movie)} AS cnt
----

The result will be one row with stating that Samuel L. Jackson played in zero movies, which is obviously a true lie.

==== Truncating relationships

The `TRUNCATE` keyword works the same way, except that as per SQL standard, it will unconditionally delete all relationship instances:

[source,sql]
----
TRUNCATE Person_ACTED_IN_Movie
----

will delete all `ACTED_IN` relationships, but none of the attached nodes.

==== Updating relationships

When you create a graph like that

[source,sql]
----
INSERT INTO Person_ACTED_IN_Movie(Person.name, ACTED_IN.role, Movie.title)
VALUES
    ('Jaret Leto', 'Ares', 'Morbius'),
    ('Greta Lee', 'Eve Kim', 'TRON Ares'),
    ('Jodie Turner-Smith', 'Elisha James', 'TRON Ares')
----

realising later that Jodie Turner-Smith played Athena, you can fix that relationship via an `UPDATE` statement:

[source,java]
----
try (var stmt = con.prepareStatement(
    "UPDATE Person_ACTED_IN_Movie SET role = ? WHERE name = ?")
) {
    stmt.setString(1, "Athena");
    stmt.setString(2, "Jodie Turner-Smith");
    stmt.executeUpdate();
}
----

The same algorithm that is used to determine which column is applied to start-node, relationship or end-node properties during insert is applied for the update.
That means you can also update properties of nodes.
But be aware that those updates will only applied via `SET` and no other `MERGE` updates are made.
That means fixing the second bug in the above graph—making sure Leto played Ares in TRON Ares, not in Morbius—creates a **second** `:Movie` node with the name `TRON Ares`:

[source,sql]
----
UPDATE Person_ACTED_IN_Movie
SET title = 'TRON Ares'
WHERE name = 'Jaret Leto'
----

will result with two `:Movie`-Nodes labeled `TRON Ares` (`SELECT count(*) FROM Movie WHERE title = 'TRON Ares'` will return 2).
